# ETL

This project implements an ETL (Extract, Transform, Load) process using AWS services for automatic processing and analysis of transaction data.

## ğŸ§© Project Overview

The pipeline loads raw data (CSV), cleans and transforms it using AWS Glue, stores it in Parquet format in Amazon S3, and enables querying through Amazon Athena.

---

## ğŸš€ Architecture

- **Amazon S3** â€” Storage for raw and processed data  
- **AWS Glue Crawler** â€” Automatically infers schema and creates a table in the Glue Data Catalog  
- **AWS Glue Job** â€” Cleans and transforms the data  
- **Amazon Athena** â€” Executes SQL queries on the processed data  
- **IAM Role** â€” Grants Glue and Athena access to required S3 buckets  

---

## ğŸ“ Data Structure

**Raw Input (CSV):**
- `UserId` â€” Unique user identifier  
- `TransactionId` â€” Unique transaction identifier  
- `TransactionTime` â€” Date and time of the transaction  
- `ItemCode` â€” Item code  
- `ItemDescription` â€” Description of the item  
- `NumberOfItemPurchased` â€” Number of items purchased  
- `CostPerItem` â€” Cost per item  
- `Country` â€” Country where the item was purchased  

**Processed Output (Parquet):**
- All columns are cleaned and standardized  
- Data types are casted correctly  
- A new column `TotalCost = NumberOfItemPurchased * CostPerItem` is added  

---

## ğŸ”„ ETL Process

1. **Upload CSV** to the `raw/` directory in S3  
2. **Glue Crawler** detects schema and creates a Glue catalog table  
3. **Glue Job** performs transformations:
   - Standardizes column names  
   - Casts correct data types  
   - Fills or removes missing values  
   - Adds calculated fields  
4. **Result** is saved to `processed/` in Parquet format  
5. **Athena** queries the processed data with SQL  

---

## ğŸ§Š Archiving Unused Data

To reduce storage costs, rarely accessed or old processed data is moved to **Amazon S3 Glacier**.

### How it works:
- Processed files in `processed/` that havenâ€™t been accessed in over 30 days are automatically transitioned to Glacier using an [S3 Lifecycle Policy](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html)  
- Retrieval is possible when needed, with delays ranging from minutes to hours

> Example lifecycle policy JSON is available in `/s3-lifecycle/lifecycle-policy.json`.

---

## ğŸ” Security and Cost Optimization

- IAM role for Glue is restricted to necessary actions only  
- Using **Parquet** format reduces data scanned and lowers Athena query costs  
- **S3 Lifecycle Policies** help automatically transition old or unused data to **S3 Glacier**, reducing long-term storage costs  
- **AWS Budgets** and alerts help monitor spending in real time  
- In the future, additional data classification and archiving strategies can be implemented to send rarely accessed processed data to **S3 Glacier**, especially useful for historical or compliance-driven data retention


---

## ğŸ“Š Sample Analytics

- Top purchased items by country  
- Average spend per user  
- Purchase trends over time  
- Anomaly detection in transactions  

---

## âœ… Benefits

- Fully automated and scalable ETL workflow  
- Fast access to cleaned and queried data  
- Minimal operational overhead  
- Cost-effective and extendable  

---

## ğŸ“ Requirements

- AWS account  
- IAM roles for Glue and Athena with appropriate S3 access  
- Raw CSV data in S3  

---




